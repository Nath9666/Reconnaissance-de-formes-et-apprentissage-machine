{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'face'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Lire les coordonnées\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m coordinates \u001b[38;5;241m=\u001b[39m \u001b[43mread_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoord_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Découper les visages en utilisant les coordonnées\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x_center, y_center, width, height) \u001b[38;5;129;01min\u001b[39;00m coordinates:\n",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m, in \u001b[0;36mread_coordinates\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m     17\u001b[0m     parts \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m---> 18\u001b[0m     x_center, y_center, width, height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, parts[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m     19\u001b[0m     coordinates\u001b[38;5;241m.\u001b[39mappend((x_center, y_center, width, height))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m coordinates\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'face'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from skimage.feature import hog\n",
    "import cv2\n",
    "\n",
    "# Fonction pour lire les coordonnées à partir d'un fichier texte\n",
    "def read_coordinates(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        coordinates = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            coordinates.append((x_center, y_center, width, height))\n",
    "        return coordinates\n",
    "\n",
    "# Chemin du dossier contenant les images et les coordonnées\n",
    "image_folder = '../assets/archive/images/train/'\n",
    "coordinates_folder = '../assets/archive/labels2/'\n",
    "\n",
    "# Lister tous les fichiers d'image\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "# Taille fixe pour les images de visage\n",
    "fixed_size = (64, 64)\n",
    "\n",
    "# Initialiser les listes pour les images de visages et les étiquettes\n",
    "face_images = []\n",
    "labels = []  # Remplacer par les étiquettes réelles associées à chaque image\n",
    "\n",
    "# Lire et traiter chaque image et ses coordonnées associées\n",
    "for idx, image_file in enumerate(image_files):\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    coord_file_path = os.path.join(coordinates_folder, image_file.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt'))\n",
    "    \n",
    "    # Lire l'image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Erreur : Impossible de charger l'image au chemin {image_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Lire les coordonnées\n",
    "    coordinates = read_coordinates(coord_file_path)\n",
    "    \n",
    "    # Découper les visages en utilisant les coordonnées\n",
    "    for (x_center, y_center, width, height) in coordinates:\n",
    "        h, w = image.shape[:2]\n",
    "        x = int((x_center - width / 2) * w)\n",
    "        y = int((y_center - height / 2) * h)\n",
    "        w = int(width * w)\n",
    "        h = int(height * h)\n",
    "        face = image[y:y+h, x:x+w]\n",
    "        resized_face = cv2.resize(face, fixed_size)  # Redimensionner à la taille fixe\n",
    "        gray_face = cv2.cvtColor(resized_face, cv2.COLOR_BGR2GRAY)  # Convertir en niveaux de gris\n",
    "        face_images.append(gray_face)\n",
    "        # Ajoutez l'étiquette correspondante ici, par exemple :\n",
    "        labels.append(idx % 2)  # Exemple : alterner entre deux classes\n",
    "\n",
    "# Convertir les listes en tableaux numpy\n",
    "face_images = np.array(face_images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Appliquer l'ACP sur les images de visages\n",
    "pca = PCA(n_components=100)\n",
    "pca_features = pca.fit_transform([face.flatten() for face in face_images])\n",
    "\n",
    "# Calculer les descripteurs HOG\n",
    "hog_features = [hog(face, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False) for face in face_images]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "from sklearn.model_selection import train_test_split\n",
    "pca_train, pca_test, labels_train, labels_test = train_test_split(pca_features, labels, test_size=0.2, random_state=42)\n",
    "hog_train, hog_test, labels_train, labels_test = train_test_split(hog_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Approches classiques de reconnaissance de visages\n",
    "\n",
    "# Utiliser l'ACP + Decision Tree\n",
    "clf_pca = DecisionTreeClassifier()\n",
    "clf_pca.fit(pca_train, labels_train)\n",
    "predictions_pca = clf_pca.predict(pca_test)\n",
    "\n",
    "# Utiliser HOG + Decision Tree\n",
    "clf_hog_dt = DecisionTreeClassifier()\n",
    "clf_hog_dt.fit(hog_train, labels_train)\n",
    "predictions_hog_dt = clf_hog_dt.predict(hog_test)\n",
    "\n",
    "# Utiliser HOG + Random Forest\n",
    "clf_hog_rf = RandomForestClassifier()\n",
    "clf_hog_rf.fit(hog_train, labels_train)\n",
    "predictions_hog_rf = clf_hog_rf.predict(hog_test)\n",
    "\n",
    "# Évaluer les performances\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy PCA: \", accuracy_score(labels_test, predictions_pca))\n",
    "print(\"Report PCA:\\n\", classification_report(labels_test, predictions_pca))\n",
    "\n",
    "print(\"Accuracy HOG + Decision Tree: \", accuracy_score(labels_test, predictions_hog_dt))\n",
    "print(\"Report HOG + Decision Tree:\\n\", classification_report(labels_test, predictions_hog_dt))\n",
    "\n",
    "print(\"Accuracy HOG + Random Forest: \", accuracy_score(labels_test, predictions_hog_rf))\n",
    "print(\"Report HOG + Random Forest:\\n\", classification_report(labels_test, predictions_hog_rf))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
