{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LF1QfgN5XWr"
      },
      "source": [
        "# Les base de Kerras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Video](https://www.loom.com/share/c20254fb8aa0456d976290b31d79194e?t=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Couche Dense\n",
        "\n",
        "Keras permet de créer des réseaux de neurones par couches.\n",
        "\n",
        "Il existe de nombreuses couches différentes comme par exemple les couches Dense. \n",
        "\n",
        "Dans une couche Dense, chaque neurone d'une couche est connecté à tous les neurones de la couche précédente\n",
        "\n",
        "Le code suivant permet de créer une couche Dense qui contient 45 neurones. Modifier le code pour qu'il contienne 60 neurones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Dense name=dense_2, built=False>\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Couche Dense Relu\n",
        "\n",
        "La plupart des neurones ont ce qu'on appelle une fonction d'activation. \n",
        "\n",
        "Il s'agit d'une fonction non linéaire qui modifie la sortie. \n",
        "\n",
        "En Keras on peut spécifier la fonction d'activation de la couche grâce au paramètre  \"activation\".\n",
        "\n",
        "\n",
        "Créer une couche Dense avec 60 neurones dont la fonction d'activation est \"relu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Dense name=dense_4, built=False>\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Premier réseau de neurone régression\n",
        "\n",
        "Il existe deux manières de créer des réseaux de neurones en Keras : l'API dite séquentielle et l'API dite fonctionnelle. \n",
        "\n",
        "Dans cet exercice on s'intéresse à  l'API séquentielle. \n",
        "\n",
        "Le code ci-dessous permet de créer un réseau de neurone à deux couches. \n",
        "\n",
        "Modifier le réseau pour que : \n",
        "\n",
        "la première couche contienne 30 neurones et utilise la fonction d’activation relu\n",
        "\n",
        "La seconde couche contienne 1 neurone et utilise la fonction d'activation linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Sequential name=sequential_1, built=False>\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compiler le modèle\n",
        "\n",
        "On a créé un réseau de neurone simple qui est stocké dans la variable   model (le code est caché)\n",
        "\n",
        "Compilez le avec l'optimiseur “sgd\" et la fonction de coût \"mse\"\n",
        "\n",
        "Il est possible de mettre ces arguments sous forme de chaîne de caractère"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entraîner le modèle\n",
        "\n",
        "On dispose de données simple contenant le prix de maison en fonction de leur caractéristiques. \n",
        "\n",
        "    1. Importer le fichier csv houses.csv avec pandas\n",
        "\n",
        "    2. Faire un train_test_split de votre dataframe\n",
        "\n",
        "    3. Créer un modèle avec deux couches et compiler le modèle avec la bonne loss et l'optimiser “sgd”\n",
        "\n",
        "    4. Créer une variable X_train contenant les colonne size et nb_rooms\n",
        "\n",
        "    5. Créer une variable y_train\n",
        "\n",
        "    6. Entraîner votre modèle avec la fonction fit de votre modèle. On prendra epochs=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Nathan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: inf               \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15545394c50>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Couche softmax\n",
        "\n",
        "Expliquer à quoi sert une couche de neurone ayant une fonction d'activiation softmax \n",
        "\n",
        "Dans quels cas est-ce utilisé ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Une couche de neurones avec une fonction d'activation softmax est utilisée pour convertir les scores (aussi appelés logits) de la couche précédente en probabilités. Chaque sortie de la couche softmax représente la probabilité que l'entrée appartienne à une des classes spécifiques, avec la particularité que la somme de toutes ces probabilités est égale à 1. Cela rend la fonction softmax particulièrement utile pour les tâches de classification où l'on souhaite déterminer la probabilité d'appartenance à chaque classe possible.\n",
        "\n",
        "La fonction softmax est typiquement utilisée dans la dernière couche d'un réseau de neurones pour les tâches de classification multiclasse. Par exemple, dans un modèle destiné à reconnaître des images de chiffres (0 à 9), la couche softmax pourrait être utilisée pour indiquer la probabilité que l'image donnée appartienne à chacun des dix chiffres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Couche Dense avec softmax\n",
        "\n",
        "Créer une couche dense à l'aide de keras qui contiendrait 10 neurones et aura pour fonction d'activation  \"softmax\".\n",
        "\n",
        "Il n'y a pas besoin de créer de réseau, juste une simple couche"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Premier réseau de neurone pour la classification\n",
        "\n",
        "On veut faire un petite réseau de neurone pour faire de la classification de tumeur (bénin / malin) à partir de deux caractéristiques.\n",
        "\n",
        "Créer un réseau de neurone avec : \n",
        "\n",
        "    1. Une première couche contenant 20 neurones et avec la fonction d'activation relu. Il faudra spécifier l'argument input_shape.\n",
        "\n",
        "    2. Une seconde couche avec fonction d'activation softmax (quel est le bon nombre de neurones ?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Nathan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entraînement d'un modèle de classification Dense\n",
        "\n",
        "On veut faire de la classification de tumeur (bénin ou cancéreux) à partir de deux caractéristique (la taille et la concentration en protéine p53). \n",
        "\n",
        "    1. Avec pandas, charger le fichier tumors.csv dans un dataframe nommé df\n",
        "\n",
        "    2. Faire un train_test_split des données\n",
        "\n",
        "    3. Créer une variable X_train avec les colonne size et p53_concentration et une variable y_train\n",
        "\n",
        "    4. Créer un réseaux de neurones avec 2 couches. La première aura 5 neurones respectivement. On utilisera une couche softmax pour la dernière couche.\n",
        "\n",
        "    5. Compiler le modèle avec la loss adéquate et l'optimiser sgd\n",
        "\n",
        "    6. Entraîner le modèle en mettant epochs= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Nathan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6926  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x15548edcc90>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Keras cross entropy loss : différences\n",
        "\n",
        "Quelle est la différence entre la binary cross entropy, la categorical_crossentropy et la sparse_categorical_entropy ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La différence entre la binary cross entropy, la categorical_crossentropy et la sparse_categorical_crossentropy réside dans le type de problème de classification qu'elles visent à résoudre et la manière dont les étiquettes (labels) sont formatées :\n",
        "\n",
        "Binary Cross Entropy : Utilisée pour les problèmes de classification binaire où chaque entrée appartient à l'une des deux classes. Les étiquettes sont généralement encodées sous forme de 0 et 1. Par exemple, pour un problème de classification de mails en \"spam\" ou \"non-spam\".\n",
        "\n",
        "Categorical Crossentropy : Utilisée pour les problèmes de classification multiclasse où chaque entrée peut appartenir à une seule classe parmi plusieurs. Les étiquettes doivent être encodées sous forme de vecteurs one-hot. Par exemple, pour un problème de classification d'images où une image peut être classée comme \"chat\", \"chien\" ou \"oiseau\", l'étiquette pour \"chat\" pourrait être [1, 0, 0], pour \"chien\" [0, 1, 0], et pour \"oiseau\" [0, 0, 1].\n",
        "\n",
        "Sparse Categorical Crossentropy : C'est une variation de la categorical crossentropy qui est utilisée également pour les problèmes de classification multiclasse, mais les étiquettes sont encodées sous forme d'entiers, plutôt que de vecteurs one-hot. Cela est utile pour économiser de l'espace mémoire et du temps de calcul lorsque le nombre de classes est grand. Par exemple, pour le même problème de classification d'images mentionné ci-dessus, l'étiquette pour \"chat\" pourrait être simplement 0, pour \"chien\" 1, et pour \"oiseau\" 2.\n",
        "\n",
        "En résumé, le choix entre ces fonctions de perte dépend du type de problème de classification (binaire ou multiclasse) et de la manière dont les étiquettes sont formatées (one-hot encoding ou entiers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choix du learning rate\n",
        "\n",
        "Comment faut-il choisir le learning rate pour que le modèle apprenne ? \n",
        "\n",
        "Pourquoi il ne faut pas qu'il soit trop gros ? \n",
        "\n",
        "Que se passe-t-il si il est trop petit ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le choix du learning rate est crucial pour l'apprentissage d'un modèle, car il détermine la taille des pas que l'algorithme d'optimisation fait vers le minimum de la fonction de coût. Voici quelques principes pour choisir le learning rate :\n",
        "\n",
        "Choix du learning rate : Il n'existe pas de règle universelle pour le choix du learning rate parfait. Cependant, commencer avec un learning rate relativement petit (par exemple, 0.001) et l'ajuster en fonction des performances du modèle sur les données de validation est une pratique courante. Des techniques comme le learning rate scheduling (diminuer le learning rate au fil du temps) ou des méthodes adaptatives (Adam, RMSprop) qui ajustent le learning rate automatiquement peuvent également être utiles.\n",
        "\n",
        "Learning rate trop élevé : Si le learning rate est trop élevé, l'algorithme d'optimisation peut \"sauter\" par-dessus le minimum de la fonction de coût, entraînant une convergence instable ou même une divergence des poids du modèle. Cela signifie que le modèle ne pourra pas apprendre correctement et que la performance sur les données de validation peut empirer au lieu de s'améliorer.\n",
        "\n",
        "Learning rate trop faible : À l'inverse, si le learning rate est trop faible, l'algorithme d'optimisation avancera très lentement vers le minimum de la fonction de coût. Cela peut signifier que l'entraînement prendra beaucoup de temps et, dans certains cas, l'algorithme peut se retrouver piégé dans un minimum local au lieu de trouver le minimum global de la fonction de coût.\n",
        "\n",
        "En résumé, le learning rate doit être choisi soigneusement pour équilibrer entre une convergence rapide et stable vers le minimum de la fonction de coût sans \"sauter\" par-dessus ni avancer trop lentement. Des expérimentations et des ajustements basés sur les performances observées sont souvent nécessaires pour trouver le bon learning rate pour un problème donné."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch et epochs\n",
        "Explique ce qu'est un batch et ce qu'est une epoch.\n",
        "\n",
        "Prenez bien soin d'expliquer la différence entre les deux"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Un batch et une epoch sont deux concepts fondamentaux dans l'entraînement des réseaux de neurones :\n",
        "\n",
        "Batch : Un batch fait référence à un sous-ensemble de l'ensemble de données d'entraînement utilisé pour entraîner le modèle pour une seule itération de mise à jour des poids. Au lieu d'entraîner le modèle sur l'ensemble complet des données à chaque itération (ce qui peut être très coûteux en termes de mémoire et de temps de calcul), les données sont divisées en plusieurs petits lots (batches). Le modèle est ensuite entraîné séquentiellement sur chaque batch, permettant une mise à jour plus fréquente des poids et une convergence plus rapide. La taille du batch, souvent désignée par \"batch size\", est un hyperparamètre important qui peut affecter les performances du modèle.\n",
        "\n",
        "Epoch : Une epoch est une passe complète à travers l'ensemble des données d'entraînement. Cela signifie que chaque échantillon de l'ensemble de données a été utilisé une fois pour l'entraînement du modèle. L'entraînement d'un modèle implique généralement de nombreuses epochs, permettant au modèle de voir les données d'entraînement plusieurs fois et d'ajuster ses poids pour minimiser la fonction de perte. Plus le nombre d'epochs est élevé, plus le modèle a de chances d'apprendre de l'ensemble des données, mais cela augmente également le risque de surapprentissage, où le modèle apprend trop bien les données d'entraînement au détriment de sa capacité à généraliser à de nouvelles données.\n",
        "\n",
        "Différence principale : La différence clé entre un batch et une epoch réside dans le fait qu'un batch se réfère à l'utilisation d'un sous-ensemble de l'ensemble de données pour une mise à jour des poids, tandis qu'une epoch fait référence à une passe complète sur l'ensemble des données d'entraînement. En d'autres termes, une epoch est composée de plusieurs itérations de batches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Différence ADAM et SGD\n",
        "\n",
        "La descente de gradient stochastique n'est pas la seule méthode pour trouver le minimum de la fonction de coût. Il existe de nombreuses autres méthodes : \n",
        "\n",
        "- RMSprop\n",
        "- Adagrad\n",
        "- Adam\n",
        "\n",
        "Adam est une des variantes les plus populaires. \n",
        "\n",
        "Expliquer rapidement son fonctionnement et ses différences avec la SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ADAM et SGD (Stochastic Gradient Descent) sont deux algorithmes d'optimisation utilisés pour minimiser la fonction de coût lors de l'entraînement des modèles de machine learning, notamment les réseaux de neurones. Voici leurs principales différences et le fonctionnement d'Adam :\n",
        "\n",
        "SGD (Descente de Gradient Stochastique) : SGD met à jour les paramètres du modèle en utilisant chaque échantillon de l'ensemble de données à la fois (ou un petit batch), ce qui le rend plus rapide et moins coûteux en mémoire pour de grands ensembles de données. Cependant, SGD peut être sujet à des oscillations et à une convergence lente, surtout dans des régions de faible gradient ou pour des fonctions de coût irrégulières.\n",
        "\n",
        "Adam (Adaptive Moment Estimation) : Adam combine les idées de deux autres extensions de SGD, RMSprop et Momentum. Comme RMSprop, Adam ajuste le taux d'apprentissage de chaque paramètre individuellement, ce qui le rend efficace dans des contextes avec des gradients variables. De plus, Adam incorpore le concept de momentum en gardant une trace des gradients passés pour lisser les mises à jour des paramètres. Cela aide à accélérer la convergence, surtout dans les premières phases de l'entraînement et dans des régions de faible gradient.\n",
        "\n",
        "Différences clés :\n",
        "\n",
        "Taux d'apprentissage adaptatif : Adam ajuste le taux d'apprentissage pour chaque paramètre individuellement, tandis que SGD utilise le même taux d'apprentissage pour tous les paramètres.\n",
        "Momentum : Adam utilise le momentum en calculant la moyenne mobile exponentielle des gradients passés, ce qui aide à accélérer la convergence. SGD peut également être modifié pour inclure le momentum, mais ce n'est pas une caractéristique par défaut.\n",
        "Convergence : Adam tend à converger plus rapidement que SGD dans de nombreux cas, grâce à son ajustement adaptatif du taux d'apprentissage et à l'utilisation du momentum.\n",
        "En résumé, bien qu'Adam soit souvent préféré pour sa rapidité de convergence et son ajustement automatique du taux d'apprentissage, le choix entre Adam et SGD (avec ou sans modifications comme le momentum) peut dépendre du problème spécifique, de la taille de l'ensemble de données, et des préférences de l'utilisateur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neurone feedforward\n",
        "\n",
        "[Video de liaison de neurone](https://www.loom.com/share/b327747c1fb94c108e14354600531162)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Premier neurone feedforward\n",
        "Le neurone feedforward est le neurone le plus simple. \n",
        "\n",
        "Pour calculer sa sortie il faut enchaîner deux opérations :\n",
        "\n",
        "une combinaison linéaire des entrées du neurones avec ses paramètres.\n",
        "une fonction non linéaire (souvent appelée fonction d'activation)\n",
        "Compléter la class SigmoidNeuron qui calcule la sortie d'un seul neurone avec une fonction d'activation sigmoid\n",
        "\n",
        "Vous utiliserez comme fonction non linéaire la fonction sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
